<!DOCTYPE html>
<html lang="pt-br">
	<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Fernando Soliva">

<meta name="generator" content="Hugo 0.65.3" />
<title>AWS Simple Storage Service (S3)</title>
<link rel="shortcut icon" href="https://fernandosoliva.com/images/favicon.ico">
<link rel="stylesheet" href="https://fernandosoliva.com/css/style.css">
<link rel="stylesheet" href="https://fernandosoliva.com/css/highlight.css">



<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css">



<link href="https://fernandosoliva.com/index.xml" rel="alternate" type="application/rss+xml" title="Fernando Soliva" />


<meta property="og:title" content="AWS Simple Storage Service (S3)" />
<meta property="og:description" content="Nesse post, cobrir as propriedades do serviço S3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://fernandosoliva.com/post/aws-s3/" />
<meta property="article:published_time" content="2020-03-08T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-03-08T00:00:00+00:00" />


<meta itemprop="name" content="AWS Simple Storage Service (S3)">
<meta itemprop="description" content="Nesse post, cobrir as propriedades do serviço S3.">
<meta itemprop="datePublished" content="2020-03-08T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2020-03-08T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="2793">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="AWS Simple Storage Service (S3)"/>
<meta name="twitter:description" content="Nesse post, cobrir as propriedades do serviço S3."/>
<meta name="twitter:site" content="@https://www.twitter.com/fernandosolivas"/>


    </head>
<body>
    <nav class="main-nav">
	
		<a href='https://fernandosoliva.com'> <span class="arrow">←</span>Home</a>
	

	
 		<a href='/about/'>Sobre</a>
  	

	
		<a class="cta" href="https://fernandosoliva.com/index.xml">Subscribe</a>
	
</nav>

    <section id="wrapper">
        
        
<article class="post">
    <header>
        <h1>AWS Simple Storage Service (S3)</h1>
        <h2 class="subtitle">Nesse post, cobrir as propriedades do serviço S3.</h2>
        <h2 class="headline">
        March 8, 2020
        <br>
        
        </h2>
    </header>
    <section id="post-body">
        <p><img src="/static/s3/cover.png" alt="cover"></p>
<p>Considere esse post, minhas notas para a certificação de Solutions Architect Solutions da AWS.*</p>
<p>Iremos cobrir um dos serviços mais antigos da AWS, o Simple Storage Service (S3). S3 é um serviço object-storage, ou seja,
permite que você gerencie arquivos, entre outras características.</p>
<p>Não iremos passar por todos os aspectos do S3 e suas configurações e sim pelos principais tópicos dos simulados da
certificação.</p>
<p>*<em>Não considere esse post como fonte da verdade. Haverão erros (espero que o mínimo possível) pois serão notas que pretendo revisar durante todo processo. Feedbacks e correções serão super bem vindas na seção de comentários abaixo.</em></p>
<h2 id="características-base">Características base</h2>
<ul>
<li>S3 é baseado em objetos (arquivos)</li>
<li>Arquivos podem ser de 0 bytes a 5TB</li>
<li>O armazenamento é ilimitado</li>
<li>Arquivos são armazenado em Buckets*</li>
<li>Bucket é um namespace universal, logo ele precisa ser único na AWS</li>
<li>Ao realizar o upload de um arquivo, a resposta do S3 é um estado HTTP 200</li>
<li>Disponibilidade garantida de 99,99%</li>
<li>Garantia de durabilidade de 99,9999999999% (11 x 9s)</li>
<li>Camada de armazenamento disponível (Tiered Storage)</li>
<li>Gerenciamento de ciclo de vida</li>
<li>Versionamento</li>
<li>Encriptação</li>
<li>MFA para deleção de recursos</li>
<li>Proteção de dados através de lista de controle de acesso (ACL) e Políticas de Bucket</li>
<li>Namespace universal na AWS. Logo, o nome do Bucket deverá ser único em toda AWS.</li>
</ul>
<h2 id="principais-termos">Principais Termos</h2>
<p>Antes de falarmos mais sobre S3, é necessário que a gente fale a mesma língua. Por isso, vamos passar por alguns termos
e nomes do S3.</p>
<h4 id="buckets">Buckets</h4>
<p>Um bucket é similar a uma pasta. Vamos criar nosso primeiro Bucket.</p>
<p>No Console de Gerenciamento da AWS, vamos escolher o serviço S3.</p>
<p><img src="/static/s3/select-s3.png" alt="s3"></p>
<p>Já na página do serviço, iremos clicar no botão &ldquo;Criar bucket&rdquo; e seguir com a criação do nosso Bucket que utilizaremos daqui pra frente.</p>
<p><img src="/static/s3/create-bucket.png" alt="create-bucket">
<em>O nome do bucket será nossa url de acesso posteriormente. Esse é um dos motivos do nome ser universal. Então, escolha um nome
da sua preferência pois se tentar replicar o nome do bucket do arquivo alguém já estará utilizando.</em></p>
<p>Perceba que no footer deste modal existem 3 botões. Criaremos o bucket direto, sem rever políticas e outras opções (vamos passar por elas uma a uma).</p>
<p>Após a criação, você deve ver seu bucket criado*.</p>
<p><img src="/static/s3/create-bucket-2.png" alt="create-bucket-2"></p>
<p><em>Perceba que a coluna <strong>Acesso</strong> está com o valor: &ldquo;Bucket e objetos não públicos&rdquo;. Assim como um novo usuário no IAM, todo
bucket novo é criado sem acesso público</em>.</p>
<h4 id="objetos">Objetos</h4>
<p>Objetos são arquivos e consite em: chave, valor, identificador de versão, metadados e subrecursos (Access Control List, Torrent). A chave é o nome do arquivo e o valor é o conteúdo, uma sequência de bytes.</p>
<p>Vamos criar nosso primeiro arquivo dentro do bucket criado no passo anterior. Vamos entrar dentro do bucket e selecionar
<strong>Carregar</strong> para realizar upload de um arquivo para nosso bucket. Após concluir você deve ver seu arquivo disponível já no bucket.</p>
<p>Ao clicar no arquivo, abrirá um menu lateral com as opções de configuração deste arquivo.</p>
<p><img src="/static/s3/upload-s3.png" alt="upload-s3"></p>
<p>Perceba que a url de acesso ao S3 é formada por: [protocolo_http]://[nome_do_bucket].s3.amazonaws.com/[nome_do_arquivo],
no meu caso fica assim: <a href="https://fernandosoliva-aws-s3.s3.amazonaws.com/17.jpg">https://fernandosoliva-aws-s3.s3.amazonaws.com/17.jpg</a></p>
<p>Vamos tentar acessar essa URL?</p>
<p><img src="/static/s3/read-file-s3.png" alt="foribidden"></p>
<p>Lembra que falamos que todo bucket criado sem nenhuma configuração específica fica privado por padrão? Esse é um dos
motivos do acesso negado ao arquivo&hellip; Então, vamos trocar as configurações do nosso bucket. Dentro do seu bucket,
tem algumas abas como opção: <em>Visão geral</em>, <em>Propriedades</em>, <em>Permissões</em>, <em>Gerenciamento</em> e <em>Pontos de acesso</em>. Nesse
momento, vamos entrar na aba <strong>Permissões</strong>.</p>
<p><img src="/static/s3/public-access-config-1.png" alt="public-access-config"></p>
<p>Clique em <strong>Editar</strong> e desmarque a opção <em>Bloquear todo o acesso público</em> por enquanto. Salve e acesse novamente seu arquivo.</p>
<p><img src="/static/s3/read-file-s3.png" alt="foribidden"></p>
<p>Acesso negado novamente?! O que aconteceu?! É que essa configuração habilita com que neste bucket <strong>possa</strong> ter objetos
públicos <strong>mas não que todos objetos serão públicos neste bucket</strong>. Então, é necessário habilitar individualmente cada objeto.</p>
<p>Clique novamente em seu arquivo, desta vez com o botão direito e selecione a opção <em>Tornar público</em>. Clique na url deste
objeto e você deverá conseguir vê-lo sem problemas!</p>
<h4 id="consistência-dos-dados">Consistência dos dados</h4>
<p>Esse ponto é mais complicado realizar testes mas precisamos sempre lembrar das características da consistência de dados do S3,
são elas:</p>
<ul>
<li>Leitura imediata depois de escrita para novos objetos</li>
<li>Consistência eventual para sobrescrita e deleção de arquivos. Pode demorar um pouco para propagar a alteração realizada.</li>
</ul>
<h2 id="categorias-de-armazenamento">Categorias de Armazenamento</h2>
<p>Este é um tema bem popular dos simulados da certificação da AWS. Saber reconhecer quando utilizar cada um dos tipos
de armazenamento da AWS e lembre-se <strong>elas são aplicáveis aos objetos e não aos buckets</strong>.</p>
<p>Existem 7 tipos:</p>
<ul>
<li>Padrão</li>
<li>Divisão Inteligente em Camadas</li>
<li>Padrão - Acesso infrequente</li>
<li>Uma zona - Acesso infrequente</li>
<li>Glacier</li>
<li>Glacier Deep Archive</li>
<li>Redundância Reduzida</li>
</ul>
<p><img src="/static/s3/s3-chart.png" alt="chart">
<em>Retirado de <a href="https://aws.amazon.com/s3/storage-classes/">https://aws.amazon.com/s3/storage-classes/</a> seção Performance Chart</em></p>
<h4 id="padrão">Padrão</h4>
<p>Esse tipo é escolhido quando não escolhemos que categoria de armazenamento queremos para nosso arquivo, ele oferece alta
resiliência, disponibilidade e performance. É bom para dados que requerem acesso com frequência como os cenários de:
Distribuição de conteúdo, sites dinâmicos, dados analíticas e outras formas de dados que são acessados com frequência.</p>
<h4 id="divisão-inteligente-em-camadas">Divisão Inteligente em Camadas</h4>
<p>A <em>Divisão Inteligente em Camadas</em> é bem similar ao S3 Padrão, porém ela tem como foco otimizar os custos do seu objeto
armazenado, utilizando inteligência artificial/machine learning para identificar qual melhor <em>categoria de armazenamento</em> seu
objeto deveria estar alocado.</p>
<p>Então este tipo herda todas as características do <strong>Padrão</strong> porém tem como foco otimização. Porém também é cobrado uma taxa
de monitoramento por objetos, então fique atento, <strong>para grande escala de objetos, ele será mais caro que o padrão</strong>.</p>
<h4 id="padrão---acesso-infrequente">Padrão - Acesso infrequente</h4>
<p>Este categoria de armazenamento é indicado para dados acessados com menos frequência e que exigem acesso rápido quando necessário.
oferece os altos níveis de resiliência e throughput e a baixa latência da categoria <em>S3 Padrão</em> com taxas reduzidas por GB de armazenamento e GB de recuperação.</p>
<h4 id="uma-zona---acesso-infrequente">Uma zona - Acesso infrequente</h4>
<p>Todas os tipos da AWS oferecem replicação do seu objeto por pelo menos três zonas de disponibilidade. Esse tipo oferece
somente uma zona com custo reduzido a 20% em comparação ao <em>Padrão - Acesso infrequente</em>, então tenha em mente que,
se essa zona falhar você perderá seu arquivo. Um bom caso de uso para esse tipo é quando você pode perder o dado no S3
que é fácil de reproduzí-lo na fonte de dados.</p>
<h4 id="glacier">Glacier</h4>
<p>O Glacier é bom para armazenar dados que não necessitam retorno imediato quando solicitado com baixo custo de armazenamento,
além de oferecer altos níveis de resiliência aos seus dados com a estratégia de no mínimo três zonas de replicação de seus dados.</p>
<h4 id="glacier-deep-archive">Glacier Deep Archive</h4>
<p>O S3 Glacier Deep Archive é a classe de armazenamento mais barata do Amazon S3 e oferece suporte à retenção e
preservação digitais de longo prazo para dados que podem ser acessados uma ou duas vezes por ano.</p>
<p>Essa classe é projetada para clientes que mantêm conjuntos de dados por 7 a 10 anos ou mais para cumprir requisitos de
conformidade normativa, especialmente em setores altamente regulados como serviços financeiros, saúde e setores públicos.</p>
<p>Todos os objetos armazenados no S3 Glacier Deep Archive são replicados e armazenados em, pelo menos, três zonas de disponibilidade
distribuídas geograficamente, protegidos por 99,999999999% de resiliência e podem ser restaurados em até 12 horas._</p>
<h4 id="trocando-o-categoria-de-armazenamento">Trocando o categoria de armazenamento</h4>
<p>Para trocar o categoria de armazenamento é simples, clique em seu arquivo no S3 para um menu lateral aparecer (direita).</p>
<p><img src="/static/s3/change-storage-category.png" alt="change-category"></p>
<p>Clique em <strong>Propriedades</strong> e em seguida clique em <strong>Categoria de armazenamento</strong> e você deve ver algo similar a imagem a seguir.</p>
<p><img src="/static/s3/s3-storage-category.png" alt="price-chart"></p>
<h4 id="mais-informações">Mais informações</h4>
<p>A AWS possui uma <a href="https://aws.amazon.com/pt/s3/storage-classes/">página específica</a> sobre as características de cada um desses <em>tipos de armazenamento</em>.</p>
<p>Como S3 é um dos serviços mais antigos da AWS e um dos mais utilizados, é também um dos tópicos mais populares da prova
de certificação. Nos simulados que apliquei, existiam MUITAS perguntas baseadas em cenários para escolher qual melhor dos
<em>tipos de armazenamento</em> para meu cenário, baseado em preço, disponibilidade e throughput. Minha dica: Aprenda bem sobre
o S3 e seus <em>tipos de armazenamento</em>.</p>
<h2 id="segurança-e-encriptação">Segurança e Encriptação</h2>
<p>Como mencionado anteriormente, os buckets criados são por padrão <strong>PRIVADOS</strong> e você pode mudar o acesso a eles através de <strong>Lista de Controle de Acesso</strong>(ACL) e/ou <strong>Políticas</strong>.</p>
<p>É possível também possível configurar logs de acesso ao Bucket. Esses logs podem ser mantidos na sua conta ou enviar para outras contas.</p>
<h4 id="lista-de-controle-de-acesso-acl">Lista de controle de acesso (ACL)</h4>
<p>ACLs são aplicáveis ao bucket, então é um ponto de atenção ao liberar permissões.</p>
<p>No menu de configurações do seu bucket, na aba <strong>Permissões</strong> é possível encontrar algumas opções de permissionamento de
acesso ao seu bucket, clique em <em>Lista de Controle de Acesso</em> para configurar uma nova lista.</p>
<p><img src="/static/s3/acl.png" alt="acl"></p>
<p>Nessa imagem vemos que existem alguns tipos de configurações de ACL, uma que é fortemente aconselhada a <strong>NÃO</strong> se utilizar,
é a seção <strong>Acesso público</strong> para todos, mesmo que seja de listagem. A não ser que você tenha um bom motivo e garantia de
um ambiente controlado de permissão, é bastante aconselhável a não se utilizar este meio.</p>
<p>ACLs são ótimas para dar acesso a contas de terceiros a manusear seus objetos.</p>
<p>Um exemplo frequente é: <strong>Você faz parte de uma consultoria e precisa acessar os objetos de seu cliente no S3.
Seu seu cliente não vê necessidade de criar um usuário somente para isso acesso ao S3, então você propõe que sua conta
da AWS seja adicionada a ACL do bucket que você precisa acesso, conseguindo assim acessar o recurso necessário
sem comprometer a segurança de outros serviços de seu cliente.</strong></p>
<h4 id="encriptação">Encriptação</h4>
<p>A encriptação dos dados do S3 é feita de duas formas:</p>
<ul>
<li><strong>Em trânsito</strong>: Encriptação realizada através de SSL/TLS quando um arquivo é solicitado através de requisições HTTPS.</li>
<li><strong>Encriptação no Servidor</strong>: Essa encriptação é feita do lado do servidor através de chaves providas pelo cliente ou gerenciadas pela AWS.</li>
</ul>
<p>Nesse tópico, falaremos somente da <strong>Encriptação no Servidor</strong>. É possível realizá-la com os seguintes métodos de encriptação.</p>
<ul>
<li>Chaves Gerenciadas pelo S3 - SSE-S3</li>
<li>AWS Key Management Service (KMS)* - SSE-KMS</li>
<li>Encriptação no lado do servidor com senha provida pelo cliente - SSE-C
*KMS é um tema tratado na certificação de Segurança da AWS e por isso não utilizaremos ele neste momento.</li>
</ul>
<h2 id="encriptando-seus-dados-via-s3">Encriptando seus dados via S3</h2>
<p>Agora vamos voltar ao menu de propriedades do nosso arquivo. Uma das opções que vemos é <strong>Criptografia</strong>. Vamos clicar nela
para configurar nosso modo de criptografia e selecione <strong>AES-256</strong> e confirme.</p>
<p><img src="/static/s3/criptografia.png" alt="criptografia"></p>
<p>Veja que só existem 3 opções: <em>Nenhum</em>, <em>AES-256</em> e <em>AWS-KMS</em>.</p>
<ul>
<li><strong>Nenhum</strong>: é auto explicativo.</li>
<li><strong>AES-256</strong>: Chave e criptografia gerenciada totalmente pela AWS.</li>
<li><strong>AWS-KMS</strong>: Criptografia através de chave criada pelo serviço KMS. Como dito antes, não iremos entrar em detalhes deste meio,
mas é importante saber que o mesmo existe.</li>
</ul>
<p>A criptografia é transparente na leitura e escrita de dados via API, SDK e CLI.
<strong>Essa encriptação ocorre no arquivo salvo em disco e antes da leitura a AWS decriptografa e retorna o dado cru para visualização.
Ou seja, tem como objetivo proteger caso ocorra algum vazamento ou falha de segurança dos discos físicos que seus dados
sejam lidos sem a chave original de criptografia.</strong></p>
<p>Lembre-se:</p>
<ul>
<li>A encriptação pode ocorrer em trânsito(SSL/TLS) ou do lado do servidor.</li>
<li>A encriptação do lado do servidor é necessário habilitar.</li>
<li>Esta encriptação pode ser habilitada a nível de bucket ou de arquivos.</li>
</ul>
<h4 id="versionamento">Versionamento</h4>
<p>O versionamento é uma ferramenta essencial em um mundo de mudanças constantes e ágeis. Vamos realizar a configuração do
versionamento de nosso bucket.</p>
<p>Na aba <em>Propriedades</em> do seu bucket tem uma opção chamada <em>Controle de Versões</em>. É possível habilitar o controle de versões
selecionando a opção como a imagem a seguir.</p>
<p><img src="/static/s3/permissions.png" alt="permissions"></p>
<p>O versionamento passará a funcionar para novos objetos, então vamos enviar uma nova versão do mesmo arquivo que vinhamos
editando até o momento e habilite a visualização de versões no seu bucket.</p>
<p><img src="/static/s3/versioning.png" alt="versioning"></p>
<p>Você deve ter o comportament similar ao visto na imagem anterior. Uma versão de seu arquivo está <strong>null</strong> e outra com um
identificador auto gerado. A versão <strong>null</strong> é o arquivo antes da habilitação do versionamento.</p>
<p>Vamos deletar nosso arquivo para ver o comportamento que o versionamento realiza. Vamos ocultar as informações de versões
e apagar nosso arquivo.</p>
<p><img src="/static/s3/excluding.png" alt="excluding"></p>
<p>Habilite novamente a visualização de versões.</p>
<p><img src="/static/s3/excluded-version.png" alt="excluded-version"></p>
<p>Veja que uma versão com uma descrição <strong>Marcador de exclusão</strong> foi gerada. Esse marcador é para identificar seu arquivo excluído
e a versão do mesmo, facilitando uma recuperação rápida. Para recuperar nosso arquivo apagado, basta apagar a versão
com a descrição <strong>Marcador de exclusão</strong>.</p>
<p>Veja que ao excluir esta versão, seu arquivo estará restaurado no bucket.</p>
<p>Revendo funções de versionamento:</p>
<ul>
<li>Guarda todas as versões de alteração do arquivo, incluindo deleções.</li>
<li>Uma vez habilitado, não pode ser desabilitado*. Você precisa excluir e criar um novo Bucket.</li>
<li>Integração com Regras de Ciclo de Vida do S3.</li>
<li>Possibilidade de adicionar MFA para deleção de arquivos como mais uma camada de segurança.</li>
</ul>
<p>*É possível suspender o versionamento, porém não desabilitar permanentemente e perder as versões anteriores.</p>
<h4 id="gerenciamento-de-ciclo-de-vida">Gerenciamento de Ciclo de Vida</h4>
<p>Com o Gerenciamento de Ciclo de Vida é possível transferir seus arquivos entre as categorias de armazenamento de forma
automatizada conforme critérios que você define. Esta configuração é a nível de bucket.</p>
<p>Quando o versionamento está habilitado é possível realizar regras em versões passadas.</p>
<h2 id="configurando-o-ciclo-de-vida">Configurando o Ciclo de Vida</h2>
<p>Para configura o ciclo de vida de seu bucket, selecione a aba <strong>Gerenciamento</strong> e a opção <strong>Ciclo de Vida</strong>. Clique em
<em>Adicionar regra de ciclo de vida</em>.</p>
<p>A criação de ciclo de vida é bastante flexível e você pode criar regras de ciclo de vida para prefixo e tags específicas
ou para todos os objetos. Para nosso exemplo, iremos criar a regra para todos os objetos.</p>
<p><img src="/static/s3/lifecicle-1.png" alt="lifecicle-1"></p>
<p>Agora vem as configurações para transição das categorias de armazenamento. No meu caso eu optei em transicionar as versões
atuais com mais de 10 dias para a categoria de <em>Divisão Inteligente de Armazenamento</em>. Já para as versões anteriores
selecionei a transição para a categoria <strong>Acesso Infrequente</strong> após 10 dias como &ldquo;versão anterior&rdquo;.</p>
<p><img src="/static/s3/lifecicle-2.png" alt="lifecicle-2"></p>
<p>É possível também realizar expiração de versões. Irei selecionar a exclusão de versões anteriores após 395 dias e também
a exclusão de versões que não houve conclusão de upload e/ou apagar marcadores de exclusão expirados.</p>
<p><img src="/static/s3/lifecicle-3.png" alt="lifecicle-3"></p>
<p>Salve seu ciclo de vida para efetivar a configuração.
<img src="/static/s3/lifecicle-4.png" alt="lifecicle-4"></p>
<p>Lembre-se:</p>
<ul>
<li>Regras de ciclo de vida são a nível de bucket.</li>
<li>Ciclo de vida tem como objetivo automatizar a transição de objetos entre categorias de armazenamento e/ou exclusão de
dados não mais necessários.</li>
</ul>
<h4 id="compartilhamento-de-bucket-entre-contas">Compartilhamento de Bucket entre Contas</h4>
<p>Existem 3 formas de compartilhar Buckets através de contas:</p>
<ul>
<li>Utilizando Políticas de Bucket &amp; IAM (esse meio é aplicável a todo Bucket). Só é possível fazer através de <em>Acesso Programático</em></li>
<li>Utilizando Lista de Controle de Acesso do Bucket &amp; IAM (esse meio é aplicável a objetos individuais). Só é possível fazer através de <em>Acesso Programático</em></li>
<li>E Funções IAM Entre Contas. É possível fazer através de <em>Acesso Progrmático</em> e <em>Console de Gerenciamento AWS</em></li>
</ul>
<h4 id="replicação-entre-regiões">Replicação entre Regiões</h4>
<p>Para habilitação dessa funcionalidade é necessário habilitar o <em>Versionamento</em> tanto no bucket de origem quanto no de destino.
Arquivos já existentes antes da ativação da funcionalidade, não serão replicados entre as regiões, somente novos arquivos.</p>
<p>Vamos criar um novo bucket para utilizar como réplica de nosso bucket inicial. Este bucket precisa estar em uma região diferente.
No meu caso irei criar um bucket chamado <strong>fernandosoliva-aws-s3-replication</strong> na região de São Paulo, assim fica fácil de lembrar e achar.</p>
<p>Entrarei no painel de configuração de meu bucket inicial <strong>fernandosoliva-aws-s3</strong> e na aba <strong>Gerenciamento</strong> selecionarei
a opção <strong>Replicação</strong> e clicar em <em>Adicionar Regra</em>.</p>
<p><img src="/static/s3/replication-1.png" alt="replication-1"></p>
<p>Selecione nosso bucket de destino</p>
<p><img src="/static/s3/replication-2.png" alt="replication-2"></p>
<p>Como não habilitamos versionamento a AWS irá pedir para ligar esta funcionalidade no bucket de destino</p>
<p><img src="/static/s3/replication-3.png" alt="replication-3"></p>
<p>Dê um nome e selecione uma <a href="https://fernandosoliva.com/post/aws-iam">Função IAM</a> ou crie uma</p>
<p><img src="/static/s3/replication-4.png" alt="replication-4"></p>
<p>E revise sua replicação.</p>
<p><img src="/static/s3/replication-5.png" alt="replication-5"></p>
<p>Agora que temos nossa replicação funcionando, vamos adicionar mais um arquivo em nosso bucket e ver o comportamento de
replica acontecer.</p>
<p>Agora que vimos nossa replica funcionando, que tal deletarmos um arquivo?! O que será que deveria acontecer?!</p>
<p>Nosso arquivo não é deletado. É uma &ldquo;trava&rdquo; de proteção da AWS para que deleções erradas não sejam replicadas.</p>
<p>Relembrando alguns detalhes:</p>
<ul>
<li>O conteúdo de um bucket é replicado para uma outra região. Não é possível replicar para duas ou mais regiões.</li>
<li>As regiões devem ser diferentes. Você não pode replicar da região de São Paulo para ela mesma.</li>
<li>A replicação é feita a nível de arquivos.</li>
<li>A marca de deleção <em>não</em> é replicada. Caso queira que o arquivo seja deletado das duas regiões, é preciso deletá-lo em ambas as regiões.</li>
</ul>
<h2 id="conclusão">Conclusão</h2>
<p>Tem muita coisa ainda sobre S3, como: metadados, tags, bloqueio de objetos, CORS, distribuição de sites e outros. Porém
a distribuição de sites é um dos temas que vou tratar em outro artigo sobre o CloudFront. Apesar de ser muito utilizado
com o S3 e ser um tópico que cai com frequência nos simulados, preferi fazer um outro artigo sobre o serviço para não
criar um artigo maior do que este já está.</p>

    </section>
</article>

<footer id="post-meta" class="clearfix">
    <a href="https://twitter.com/fernandosolivas">
    <img class="avatar" src="https://fernandosoliva.com/images/avatar.png">
    <div>
        <span class="dark">Fernando Soliva</span>
        <span>Fernando Soliva - Desenvolvedor de Software</span>
    </div>
    </a>
    <section id="sharing">
        <a class="twitter" href="https://twitter.com/intent/tweet?text=https%3a%2f%2ffernandosoliva.com%2fpost%2faws-s3%2f - AWS%20Simple%20Storage%20Service%20%28S3%29 by @fernandosolivas"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

    </section>
</footer>

<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "fernandosoliva" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="https://fernandosoliva.com/post/aws-iam/">AWS Identity and Access Management<aside class="dates">Mar 2 2020</aside></a>
        </li>
    
        <li>
            <a href="https://fernandosoliva.com/post/personal-site-5-minutes/">Criando seu site em 5 minutos e de graça<aside class="dates">Feb 29 2020</aside></a>
        </li>
    
</ul>



        <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/fernandosolivas">
        <i class="fa fa-github"></i>
    </a>
    
    <a class="symbol" href="https://www.linkedin.com/in/fernandosoliva/">
        <i class="fa fa-linkedin"></i>
    </a>
    
    <a class="symbol" href="https://dev.to/fernandosolivas">
        <i class="fa fa-medium"></i>
    </a>
    
    <a class="symbol" href="https://www.twitter.com/fernandosolivas">
        <i class="fa fa-twitter"></i>
    </a>
    


</div>

    
    <p class="small">
    
        © Copyright 2020 Fernando Soliva
    
    </p>
</footer>

    </section>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="https://fernandosoliva.com/js/main.js"></script>
<script src="https://fernandosoliva.com/js/highlight.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-159908819-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>
